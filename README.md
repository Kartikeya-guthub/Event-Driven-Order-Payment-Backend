# ğŸš€ Event-Driven Order & Payment System

<div align="center">

![Node.js](https://img.shields.io/badge/Node.js-18+-339933?style=for-the-badge&logo=node.js&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)

**A production-ready event-driven microservice demonstrating advanced distributed systems patterns**

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Quick Start](#-quick-start) â€¢ [Verification](#-correctness-guarantees) â€¢ [Demo](#-live-demo)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Correctness Guarantees](#-correctness-guarantees-with-proof)
- [Tech Stack](#-tech-stack)
- [Quick Start](#-quick-start)
- [API Documentation](#-api-documentation)
- [Database Schema](#-database-schema)
- [Observability](#-observability)
- [Live Demo](#-live-demo)
- [Testing](#-testing)
- [Project Structure](#-project-structure)

---

## ğŸ¯ Overview

This project implements a **production-grade event-driven order and payment processing system** using the **Transactional Outbox Pattern** and **idempotent consumer patterns**. It demonstrates how to build resilient, scalable microservices that guarantee **exactly-once side-effect semantics** (not exactly-once delivery, which is impossible with Kafka's at-least-once guarantee).

### Why This Project Matters

Most developers build CRUD APIs. This project showcases:
- âœ… **Event-driven architecture** with guaranteed delivery
- âœ… **Distributed transaction handling** without 2PC
- âœ… **Idempotency** and duplicate detection
- âœ… **Retry logic** with dead-letter queues
- âœ… **Observability** through structured logging
- âœ… **Concurrency control** with optimistic locking

---

## âœ¨ Features

### Core Capabilities

| Feature | Description | Status |
|---------|-------------|--------|
| ğŸ”„ **Transactional Outbox** | Atomic DB writes + event publishing | âœ… Complete |
| ğŸ¯ **Idempotency** | Duplicate event detection & prevention | âœ… Complete |
| ğŸ”’ **Optimistic Locking** | Version-based concurrency control | âœ… Complete |
| â™»ï¸ **Retry Logic** | Controlled retries with exponential backoff | âœ… Complete |
| ğŸ’€ **Dead Letter Queue** | Poison message handling | âœ… Complete |
| ğŸ“Š **Structured Logging** | JSON logs for observability | âœ… Complete |
| ğŸ“ˆ **Metrics** | Real-time system health monitoring | âœ… Complete |
| ğŸ” **State Machine** | Deterministic order state transitions | âœ… Complete |

### Advanced Patterns Implemented

1. **Transactional Outbox Pattern**
   - Ensures events are never lost
   - Atomic database write + event publishing
   - Survives publisher crashes

2. **Event-Driven Architecture**
   - OrderCreated â†’ PaymentPending â†’ OrderPaid/OrderFailed
   - Asynchronous payment processing
   - Event replay capability

3. **Idempotency & Deduplication**
   - `processed_events` table tracks handled events
   - Safe Kafka message redelivery
   - No duplicate order processing

4. **Optimistic Locking**
   - Version-based concurrency control
   - Prevents lost updates in concurrent scenarios
   - Race condition handling

5. **Failure Handling**
   - Automatic retries (max 3 attempts)
   - Dead-letter queue for poison messages
   - Graceful degradation

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ POST /orders
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server    â”‚ â”€â”€â”€â”€â–º Insert Order (CREATED)
â”‚  (Express.js)   â”‚ â”€â”€â”€â”€â–º Insert Event to Outbox
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PostgreSQL Database              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  orders  â”‚  â”‚ outbox  â”‚  â”‚processedâ”‚ â”‚
â”‚  â”‚          â”‚  â”‚         â”‚  â”‚ events  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Outbox Publisher â”‚ â”€â”€â”€â”€â–º Poll outbox table
â”‚   (Background)  â”‚ â”€â”€â”€â”€â–º Publish to Kafka
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â”€â”€â–º Mark as published
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Kafka   â”‚
â”‚  order-events   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Payment Worker   â”‚ â”€â”€â”€â”€â–º Consume events
â”‚  (Consumer)     â”‚ â”€â”€â”€â”€â–º Process payment
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â”€â”€â–º Update order state
                    â”€â”€â”€â”€â–º Emit OrderPaid/Failed
```

### Event Flow

```
OrderCreated Event
       â†“
  Idempotency Check â”€â”€â” (duplicate?) â†’ Skip
       â†“              â””â”€â”€ (new) â†’ Continue
  Update: PAYMENT_PENDING
       â†“
  Process Payment â”€â”€â” (success) â†’ OrderPaid Event
       â†“            â””â”€â”€ (failed)  â†’ OrderFailed Event
  Update State
       â†“
  Publish Follow-up Event
```

---

## ğŸ”¥ Correctness Guarantees (with Proof)

This system guarantees the following properties:

### 1ï¸âƒ£ **No Order is Processed Twice**

**Guarantee:** Even if Kafka delivers the same message multiple times, the order is processed exactly once.

**Mechanism:** 
- `processed_events` table with unique constraint on `(event_id, worker_id)`
- Worker checks this table before processing

**Proof:**
```sql
-- Event processed once
SELECT COUNT(*) FROM processed_events WHERE event_id = 'abc-123';
-- Result: 1 (always)

-- Even after Kafka redelivery
SELECT state FROM orders WHERE id = 'order-1';
-- State doesn't change on duplicate delivery
```

### 2ï¸âƒ£ **Events Are Not Lost (Even if Publisher Crashes)**

**Guarantee:** If the system crashes after saving an order, the event will still be published when the system restarts.

**Mechanism:**
- Transactional Outbox Pattern
- Events saved in DB transaction with order
- Publisher polls unpublished events

**Proof:**
```sql
-- Create order (crashes before publishing)
INSERT INTO orders...
INSERT INTO outbox...
COMMIT; -- â† Crash here

-- After restart, publisher finds unpublished event
SELECT * FROM outbox WHERE published_at IS NULL;
-- Event is still there and will be published
```

### 3ï¸âƒ£ **Duplicate Kafka Messages Are Handled Safely**

**Guarantee:** Replaying the same Kafka message doesn't cause side effects.

**Mechanism:**
- Idempotency check before any business logic
- Database constraint prevents duplicate inserts

**Proof:**
```bash
# Publish same event twice
kafka-console-producer --topic order-events
> {"eventId": "abc-123", ...}
> {"eventId": "abc-123", ...}  # Duplicate

# Worker logs show:
# First: "Processing event abc-123"
# Second: "DUPLICATE_EVENT detected, skipping"
```

### 4ï¸âƒ£ **Order State Transitions Are Deterministic**

**Guarantee:** Orders follow a strict state machine: `CREATED â†’ PAYMENT_PENDING â†’ PAID/FAILED`

**Mechanism:**
- Optimistic locking with version numbers
- State transition validation in SQL

**Proof:**
```sql
-- Only valid transitions succeed
UPDATE orders SET state = 'PAID' 
WHERE id = ? AND state = 'PAYMENT_PENDING' AND version = 1;
-- âœ… Succeeds

UPDATE orders SET state = 'PAID' 
WHERE id = ? AND state = 'CREATED';
-- âŒ Fails (invalid transition)
```

### 5ï¸âƒ£ **System Recovers from Worker Crashes**

**Guarantee:** If a worker crashes mid-processing, the event is redelivered and processed.

**Mechanism:**
- Kafka consumer groups with offset commits
- Only commit offset after successful processing

**Proof:**
```
1. Worker receives event
2. Worker crashes (no offset commit)
3. Worker restarts
4. Kafka redelivers event (offset not committed)
5. Worker processes event successfully
6. Worker commits offset
```

---

## âš ï¸ Known Limitations & Tradeoffs

This section documents **known limitations** for transparency. Every distributed system has tradeoffs.

### 1ï¸âƒ£ **Not True Exactly-Once Delivery**

**Claim:** "Exactly-once side-effect semantics"

**Reality:** 
- Kafka provides **at-least-once delivery** (messages may be duplicated)
- System achieves **idempotent side-effects** through deduplication
- This is **not** the same as exactly-once delivery

**Why it matters:** In interviews, distinguish "exactly-once effects" from "exactly-once delivery."

---

### 2ï¸âƒ£ **Crash Window - Payment May Be Skipped**

**Scenario:**
```
1. Worker receives OrderCreated event
2. Worker inserts into processed_events (marks as handled)
3. ğŸ’¥ Worker crashes HERE
4. Payment service never called
5. Worker restarts
6. Event is marked as processed â†’ skipped
7. Order is stuck in PAYMENT_PENDING state
```

**Impact:** Small failure window where payment is lost.

**Mitigation strategies (not implemented):**
- Use database transactions for idempotency check + payment call (requires payment service to support transactions)
- Implement timeout-based monitoring (alert if order in PAYMENT_PENDING > 5 minutes)
- Use scheduled job to retry stuck orders

**Current tradeoff:** Simplicity over 100% correctness. Acceptable for demo; would need fix for production.

---

### 3ï¸âƒ£ **Synchronous Retries Block Partition**

**Current implementation:**
```javascript
while (retryCount < MAX_RETRIES) {
  try {
    await processPayment(); // Blocks partition
  } catch (error) {
    retryCount++;
    await sleep(1000); // Partition is blocked
  }
}
```

**Impact:** 
- While retrying, the entire Kafka partition is blocked
- Other events in the partition cannot be processed
- Reduces throughput under failure scenarios

**Production alternatives (not implemented):**
- **Retry topic pattern**: Publish failed events to separate retry topic with delay
- **Scheduled retry queue**: Use external scheduler (e.g., AWS SQS with visibility timeout)
- **Async retry workers**: Dedicated workers for retry processing

**Current tradeoff:** Simplicity over scalability. Acceptable for demo; would need optimization for high throughput.

---

### 4ï¸âƒ£ **Single Worker Type (Composite PK Unused)**

**Database design:**
```sql
PRIMARY KEY (event_id, worker_id)
```

**Intended use:** Allow different worker types to process the same event (e.g., payment-worker, notification-worker).

**Current reality:** Only one worker type (`payment-worker`) exists.

**Why the discrepancy:** Future-proofing. Design allows multiple worker types without schema migration.

**Interview note:** Be honest that this is unused capacity, not active functionality.

---

### 5ï¸âƒ£ **No Circuit Breaker for Payment Service**

**Current behavior:** If payment service is down, every request retries 3 times.

**Impact:** Cascading failures, wasted resources.

**Production solution:** Implement circuit breaker (e.g., using `opossum` library) to fail fast after detecting service is down.

---

### 6ï¸âƒ£ **Event Replay Not Implemented**

**What's missing:** Ability to reprocess events from Kafka history for data recovery.

**Why it matters:** If database corruption occurs, cannot rebuild state from events.

**Note:** This system is **event-driven** but **not event-sourced**. The database is the source of truth, not the event log.

---

## ğŸ› ï¸ Tech Stack

| Category | Technology | Purpose |
|----------|-----------|---------|
| **Runtime** | Node.js 18+ | JavaScript runtime |
| **Framework** | Express.js | REST API server |
| **Database** | PostgreSQL 15+ | Relational data & outbox |
| **Message Broker** | Apache Kafka 3.x | Event streaming |
| **Container** | Docker & Docker Compose | Service orchestration |
| **Libraries** | kafkajs, uuid, dotenv | Kafka client, UUID generation |

---

## ğŸš€ Quick Start

### Prerequisites

- Docker Desktop (running)
- Node.js 18+
- PostgreSQL client (psql)
- Git

### 1. Clone & Install

```bash
git clone https://github.com/Kartikeya-guthub/Event-Driven-Order-Payment-Backend.git
cd Event-Driven-Order-Payment-Backend
npm install
```

### 2. Start Infrastructure

```bash
# Start Kafka, Zookeeper, PostgreSQL
docker-compose up -d

# Verify services are running
docker ps
```

### 3. Run Database Migrations

```bash
# Connect to PostgreSQL
$env:PGPASSWORD='app_password'
psql -h localhost -U app_user -d app_db -f db/migrations/001_init.sql
psql -h localhost -U app_user -d app_db -f db/migrations/002_dead_letter_events.sql
```

### 4. Start Application Services

```bash
# Terminal 1: API Server
npm run dev

# Terminal 2: Outbox Publisher
node src/publisher/outboxPublisher.js

# Terminal 3: Payment Worker
node src/worker/consumer.js
```

### 5. Create Your First Order

```bash
# PowerShell
$body = @{userId = "550e8400-e29b-41d4-a716-446655440001"; amount = 299.99} | ConvertTo-Json
curl -Method POST -Uri http://localhost:3000/orders -Body $body -ContentType "application/json" -UseBasicParsing
```

**Expected Response:**
```json
{
  "orderId": "85136923-023b-4304-a9c7-dcb4dde2eab4",
  "state": "CREATED"
}
```

---

## ğŸ“¡ API Documentation

### Create Order

**Endpoint:** `POST /orders`

**Request Body:**
```json
{
  "userId": "550e8400-e29b-41d4-a716-446655440001",
  "amount": 299.99
}
```

**Response:** `201 Created`
```json
{
  "orderId": "uuid",
  "state": "CREATED"
}
```

**Error Response:** `500 Internal Server Error`
```json
{
  "error": "Failed to create order"
}
```

---

## ğŸ—„ï¸ Database Schema

### Tables

#### `orders`
```sql
CREATE TABLE orders (
  id UUID PRIMARY KEY,
  user_id UUID NOT NULL,
  amount DECIMAL(10,2) NOT NULL,
  state VARCHAR(50) NOT NULL,
  version INTEGER DEFAULT 1,
  created_at TIMESTAMPTZ DEFAULT now(),
  updated_at TIMESTAMPTZ DEFAULT now()
);
```

#### `outbox`
```sql
CREATE TABLE outbox (
  event_id UUID PRIMARY KEY,
  aggregate_type VARCHAR(50) NOT NULL,
  aggregate_id UUID NOT NULL,
  event_type VARCHAR(50) NOT NULL,
  payload JSONB NOT NULL,
  created_at TIMESTAMPTZ DEFAULT now(),
  published_at TIMESTAMPTZ
);
```

#### `processed_events`
```sql
CREATE TABLE processed_events (
  event_id UUID NOT NULL,
  worker_id VARCHAR(100) NOT NULL,
  processed_at TIMESTAMPTZ DEFAULT now(),
  PRIMARY KEY (event_id, worker_id)
);
```

#### `dead_letter_events`
```sql
CREATE TABLE dead_letter_events (
  event_id UUID PRIMARY KEY,
  event_type TEXT,
  aggregate_id UUID,
  payload JSONB,
  failed_at TIMESTAMPTZ DEFAULT now(),
  reason TEXT
);
```

---

## ğŸ“Š Observability

### Structured Logs

All services emit JSON-formatted logs:

```json
{
  "service": "payment-worker",
  "type": "EVENT_RECEIVED",
  "eventId": "abc-123",
  "eventType": "OrderCreated"
}
```

**Log Types:**
- `STARTUP` - Service initialization
- `EVENT_RECEIVED` - Kafka message received
- `DUPLICATE_EVENT` - Duplicate detected
- `STATE_CHANGE` - Order state updated
- `PAYMENT_RESULT` - Payment success/failure
- `PROCESSING_ERROR` - Error during processing
- `DLQ_EVENT` - Event moved to dead-letter queue
- `METRICS` - System metrics (every 10s)

### Metrics

Real-time metrics printed every 10 seconds:

```json
{
  "service": "payment-worker",
  "type": "METRICS",
  "eventsProcessed": 145,
  "duplicatesSkipped": 12,
  "paymentsSuccess": 98,
  "paymentsFailed": 35,
  "retriedEvents": 8,
  "dlqEvents": 2
}
```

---

## ğŸ¬ Live Demo

### Complete Order Flow Demonstration

#### Step 1: Verify System is Running
```bash
# Check Docker services
docker ps

# Expected output:
# kafka, zookeeper, pg_local, pgadmin (all running)
```

#### Step 2: Create an Order
```bash
$body = @{userId = "550e8400-e29b-41d4-a716-446655440001"; amount = 199.99} | ConvertTo-Json
curl -Method POST -Uri http://localhost:3000/orders -Body $body -ContentType "application/json" -UseBasicParsing
```

#### Step 3: Verify Order in Database
```bash
$env:PGPASSWORD='app_password'
psql -h localhost -U app_user -d app_db -c "SELECT id, state, version FROM orders ORDER BY created_at DESC LIMIT 1;"
```

**Expected:**
```
                  id                  |      state       | version
--------------------------------------+------------------+---------
 85136923-023b-4304-a9c7-dcb4dde2eab4 | CREATED          |       1
```

#### Step 4: Verify Outbox Event
```bash
psql -h localhost -U app_user -d app_db -c "SELECT event_id, event_type, published_at FROM outbox ORDER BY created_at DESC LIMIT 1;"
```

**Expected:**
```
               event_id               |  event_type  | published_at
--------------------------------------+--------------+--------------
 e99a8f89-27db-4f0c-8f5c-598ec6de63e3 | OrderCreated | (timestamp)
```

#### Step 5: Watch Worker Process Payment
```
# Worker logs will show:
{
  "service": "payment-worker",
  "type": "EVENT_RECEIVED",
  "eventId": "e99a8f89-27db-4f0c-8f5c-598ec6de63e3",
  "eventType": "OrderCreated"
}
{
  "service": "payment-worker",
  "type": "STATE_CHANGE",
  "orderId": "85136923-023b-4304-a9c7-dcb4dde2eab4",
  "newState": "PAYMENT_PENDING"
}
{
  "service": "payment-worker",
  "type": "PAYMENT_RESULT",
  "orderId": "85136923-023b-4304-a9c7-dcb4dde2eab4",
  "status": "SUCCESS"
}
{
  "service": "payment-worker",
  "type": "STATE_CHANGE",
  "orderId": "85136923-023b-4304-a9c7-dcb4dde2eab4",
  "newState": "PAID"
}
```

#### Step 6: Verify Final State
```bash
psql -h localhost -U app_user -d app_db -c "SELECT id, state, version FROM orders WHERE id = '85136923-023b-4304-a9c7-dcb4dde2eab4';"
```

**Expected:**
```
                  id                  | state | version
--------------------------------------+-------+---------
 85136923-023b-4304-a9c7-dcb4dde2eab4 | PAID  |       3
```

#### Step 7: Test Idempotency (Duplicate Detection)
```bash
# Manually republish the same event to Kafka
# Worker will skip it and log:
{
  "service": "payment-worker",
  "type": "DUPLICATE_EVENT",
  "eventId": "e99a8f89-27db-4f0c-8f5c-598ec6de63e3"
}

# Order state remains unchanged
```

#### Step 8: View System Metrics
```bash
# Worker periodically logs metrics:
{
  "service": "payment-worker",
  "type": "METRICS",
  "eventsProcessed": 1,
  "duplicatesSkipped": 0,
  "paymentsSuccess": 1,
  "paymentsFailed": 0,
  "retriedEvents": 0,
  "dlqEvents": 0
}
```

---

## ğŸ§ª Testing

### Manual Verification Steps

#### Test 1: Idempotency
```bash
# Create order
curl -X POST http://localhost:3000/orders -d '{"userId":"...","amount":100}'

# Wait 3 seconds for processing

# Get order state
psql ... -c "SELECT state FROM orders WHERE id = '<orderId>';"
# Result: PAID

# Simulate duplicate (republish same Kafka event)
# ... manual Kafka republish ...

# Check order state again
psql ... -c "SELECT state FROM orders WHERE id = '<orderId>';"
# Result: PAID (unchanged)

# âœ… PASS: Order not processed twice
```

#### Test 2: Transactional Outbox
```bash
# Stop publisher
# Create order
curl -X POST http://localhost:3000/orders ...

# Check outbox (unpublished)
psql ... -c "SELECT published_at FROM outbox ORDER BY created_at DESC LIMIT 1;"
# Result: NULL

# Start publisher

# Check outbox (now published)
psql ... -c "SELECT published_at FROM outbox ORDER BY created_at DESC LIMIT 1;"
# Result: <timestamp>

# âœ… PASS: Event published after crash recovery
```

#### Test 3: Retry Logic
```bash
# Force payment failures in paymentService.js
# Create 5 orders rapidly
for ($i=1; $i -le 5; $i++) {
  curl -X POST http://localhost:3000/orders -d "{\"userId\":\"...\",\"amount\":$i00}"
}

# Watch worker logs for retries:
# PROCESSING_ERROR (retry 1)
# PROCESSING_ERROR (retry 2)
# PROCESSING_ERROR (retry 3)
# DLQ_EVENT (moved to dead-letter queue)

# Check DLQ
psql ... -c "SELECT COUNT(*) FROM dead_letter_events;"
# Result: > 0

# âœ… PASS: Failed events moved to DLQ after retries
```

### Automated Integration Tests

Run the complete integration test suite:

```bash
# Ensure all services are running first:
# - docker-compose up -d
# - npm run dev (Terminal 1)
# - node src/publisher/outboxPublisher.js (Terminal 2)
# - node src/worker/consumer.js (Terminal 3)

# Run integration tests
npm run test:integration
```

**What the tests verify:**

| Test | Verification |
|------|--------------|
| **Complete Order Flow** | Order creation â†’ Event publishing â†’ Payment processing â†’ State updates |
| **Idempotency** | Duplicate events are detected and skipped |
| **Transactional Outbox** | Order and outbox event saved atomically |
| **Optimistic Locking** | Version-based concurrency control prevents conflicts |
| **State Machine** | Valid state transitions enforced |

**Example Output:**
```
ğŸ§ª Starting Integration Tests

ğŸ“‹ Test 1: Complete Order Flow (Happy Path)
  âœ“ Order created: 85136923-023b-4304-a9c7-dcb4dde2eab4
  âœ“ Order persisted with state: CREATED
  âœ“ Outbox event created: OrderCreated
  âœ“ Event published at: 2026-02-15T14:23:45.123Z
  âœ“ Payment processed: PAID
  âœ“ Event marked as processed in processed_events table
  âœ“ Version correctly incremented to: 3
âœ… Test 1 PASSED

ğŸ“‹ Test 2: Idempotency - Duplicate Event Handling
  âœ“ Order created: a1b2c3d4-e5f6-4789-a012-3456789abcdef
  âœ“ Initial state: PAID, version: 3
  âœ“ Event already in processed_events table
  âœ“ Order state unchanged (version: 3)
âœ… Test 2 PASSED

...

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Test Summary
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Passed: 5/5
âŒ Failed: 0/5
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‰ All integration tests passed!
```

---

## ğŸ“ Project Structure

```
event-driven-order-payment/
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ connection.js           # PostgreSQL connection pool
â”‚   â””â”€â”€ migrations/
â”‚       â”œâ”€â”€ 001_init.sql        # Initial schema
â”‚       â””â”€â”€ 002_dead_letter_events.sql
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.js                  # Express API server
â”‚   â”œâ”€â”€ mock/
â”‚   â”‚   â””â”€â”€ paymentService.js   # Mock payment processor
â”‚   â”œâ”€â”€ publisher/
â”‚   â”‚   â””â”€â”€ outboxPublisher.js  # Outbox event publisher
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ orders.js           # Order routes
â”‚   â””â”€â”€ worker/
â”‚       â””â”€â”€ consumer.js         # Kafka consumer (payment worker)
â”œâ”€â”€ test/
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ orderFlow.test.js   # Integration tests
â”œâ”€â”€ docker-compose.yml          # Docker services configuration
â”œâ”€â”€ package.json
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ DEMO.md                     # Step-by-step demo guide
â””â”€â”€ README.md
```

---

## ğŸ“ Learning Outcomes

This project demonstrates understanding of:

1. **Event-Driven Architecture**
   - Asynchronous message processing
   - Event-driven communication (not event sourcing)
   - Eventual consistency

2. **Distributed Systems Patterns**
   - Transactional Outbox Pattern
   - Idempotent Consumer Pattern
   - Optimistic Locking
   - Dead-Letter Queue Pattern

3. **Reliability Engineering**
   - Retry mechanisms
   - Dead-letter queues
   - Graceful degradation
   - Observability

4. **Data Consistency**
   - Atomic operations
   - State machines
   - Concurrency control
   - Deduplication

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---


## ğŸ‘¨â€ğŸ’» Author

**Kartikeya**

- GitHub: [@Kartikeya-guthub](https://github.com/Kartikeya-guthub)
- LinkedIn: [Connect](https://www.linkedin.com/in/kartikeya-sharma-94b30a296/)

---

## ğŸ™ Acknowledgments

This project was built to demonstrate production-ready event-driven architecture patterns suitable for enterprise microservices.

---

<div align="center">

**â­ Star this repo if you found it helpful!**

**Built with â¤ï¸ using Node.js, Kafka, and PostgreSQL**

</div>
